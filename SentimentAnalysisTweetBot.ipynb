{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa275069-c96f-4d55-882e-69317d8f6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "account= \"@UserName\"\n",
    "consumerKey = \".........................\"\n",
    "consumerSecret = \".........................\"\n",
    "accessToken = \".........................\"\n",
    "accessTokenSecret = \".........................\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f2b534-5328-4e61-8954-7f5bb8e28303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "\n",
    "# ツイートを監視し、自分へのメンションがあった場合、指定されたキーワードとツイート数からツイートを取得、分析し、結果をリプライするクラス\n",
    "class SentimentAnalysisTweetBot(tweepy.Stream):\n",
    "    \n",
    "    def __init__(self, consumerKey, consumerSecret, accessToken, accessTokenSecret) : \n",
    "        super().__init__(consumerKey, consumerSecret, accessToken, accessTokenSecret)\n",
    "        self.api = self.initTwitterAPI(consumerKey, consumerSecret, accessToken, accessTokenSecret)\n",
    "        \n",
    "    def on_status(self, status):\n",
    "        print(status.user.screen_name + \" : \" +status.text)\n",
    "        line = status.text.split(\" \")\n",
    "        keyword = line[1]\n",
    "        noOfTweet = int(line[2])\n",
    "        detail = False\n",
    "        if len(line) > 3 :\n",
    "            if line[3] == \"detail\" : detail = True\n",
    "            else : detail = False\n",
    "        tweets = self.getTweets(self.api, keyword, noOfTweet)\n",
    "        tweet_df = self.sentimentAnalyzer(tweets)\n",
    "        self.tweetResult(tweet_df, status.user.screen_name, status.id, detail)\n",
    "    \n",
    "        detail = False\n",
    "        print(\"------fin------\")\n",
    "        print(\"searching...\")\n",
    "        \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            print(\"420 error\")\n",
    "            return False\n",
    "        \n",
    "    # APIの設定\n",
    "    def initTwitterAPI(self, consumerKey, consumerSecret, accessToken, accessTokenSecret) :\n",
    "        auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "        auth.set_access_token(accessToken, accessTokenSecret)\n",
    "        api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "        return api\n",
    "    \n",
    "    def getTweets(self, api, keyword, noOfTweet):\n",
    "        # キーワードの分割\n",
    "        keyword_list = keyword.split(\",\")\n",
    "        # リツイートは取得しない\n",
    "        keyword += \"-filter:retweets\"\n",
    "        # ツイートの取得\n",
    "        tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "        return tweets\n",
    "    \n",
    "        # sentimentのグループごとに数と割合を返す関数\n",
    "    def count_values_in_column(self, data,feature):\n",
    "        total=data.loc[:,feature].value_counts(dropna=False)\n",
    "        percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "        return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "\n",
    "    \n",
    "    def sentimentAnalyzer(self, tweets):\n",
    "        # 元ツイート\n",
    "        tweet_list_original = pd.DataFrame([tweet.text for tweet in tweets], columns=[\"original\"])\n",
    "\n",
    "        # 重複削除\n",
    "        tweet_list_original.drop_duplicates()\n",
    "\n",
    "        # 英語に翻訳\n",
    "        translator = Translator()\n",
    "        tweet_list_translated = [] # 英語に翻訳したツイート\n",
    "        for tweet in tweet_list_original[\"original\"] :\n",
    "            if detect(tweet)==\"en\" :\n",
    "                tweet_list_translated.append(tweet)\n",
    "            else:\n",
    "                tweet_list_translated.append(translator.translate(tweet, dest='en').text)\n",
    "\n",
    "        tweet_list_translated = pd.DataFrame(tweet_list_translated)\n",
    "\n",
    "        # ツイート情報\n",
    "        tweet_df = pd.DataFrame()\n",
    "        tweet_df[\"original\"] = tweet_list_original\n",
    "        tweet_df[\"translated\"] = tweet_list_translated\n",
    "\n",
    "        # 感情分析\n",
    "        tweet_df[['polarity', 'subjectivity']] = tweet_df['translated'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "        for index, row in tweet_df['translated'].iteritems():\n",
    "            score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "            neg = score['neg']\n",
    "            neu = score['neu']\n",
    "            pos = score['pos']\n",
    "            comp = score['compound']\n",
    "\n",
    "            if neg > pos: \n",
    "                if neg>0.25 : tweet_df.loc[index, 'sentiment'] = \"strong_negative\"\n",
    "                else : tweet_df.loc[index, 'sentiment'] = \"negative\"\n",
    "            elif pos > neg: \n",
    "                if pos>0.25 : tweet_df.loc[index, \"sentiment\"] = \"strong_positive\"\n",
    "                else : tweet_df.loc[index, \"sentiment\"] = \"positive\"\n",
    "            else: tweet_df.loc[index, 'sentiment'] = \"neutral\"\n",
    "            tweet_df.loc[index, 'neg'] = neg\n",
    "            tweet_df.loc[index, 'neu'] = neu\n",
    "            tweet_df.loc[index, 'pos'] = pos\n",
    "            tweet_df.loc[index, 'compound'] = comp\n",
    "        return tweet_df\n",
    "    \n",
    "#     分析結果をツイートする\n",
    "    def tweetResult(self, tweet_df, screen_name, reply_id, detail):\n",
    "        \n",
    "        greeting = \"\"\n",
    "        \n",
    "        if detail==False :\n",
    "            for index, row in tweet_df.iterrows():\n",
    "                if row[\"sentiment\"] == \"strong_negative\": tweet_df.loc[index, \"sentiment\"] = \"アンチかも\"\n",
    "                else : tweet_df.loc[index, \"sentiment\"] = \"アンチじゃないよ\"\n",
    "                    \n",
    "            greeting += \"アンチの割合を調べました\\n\"\n",
    "        else :\n",
    "            greeting += \"詳しく調べました\\n\"\n",
    "        \n",
    "#         アンチコメントとみなされたツイートを表示する例\n",
    "#         for index, row in tweet_df[tweet_df[\"sentiment\"]==\"アンチかも\"].iterrows() : \n",
    "#             print(row.original)\n",
    "#             print(\"-------------------------------------------\")\n",
    "\n",
    "        sentimentRate_df = self.count_values_in_column(tweet_df, \"sentiment\")\n",
    "    \n",
    "        print(sentimentRate_df)\n",
    "    \n",
    "        reply = \"@\"+str(screen_name)+\"\\n\"+greeting+str(sentimentRate_df);\n",
    "        self.api.update_status(reply, in_reply_to_status_id = reply_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cddc1f8-03b5-4a36-80eb-b0822af6c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用方法\n",
    "myStreamListener = SentimentAnalysisTweetBot(consumerKey, consumerSecret, accessToken, accessTokenSecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5d4c9-57d7-4c04-a6b4-49891e5e2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStreamListener.filter(track=[account])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e5262-a6f4-49d5-be7b-f096b2afea7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
